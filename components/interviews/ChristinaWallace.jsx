import React, {Component} from 'react';

export default class ChristinaWallace extends Component {

  static Name = "Christina Wallace"

  render() {
    return (
      <div>
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          I've been talking to a lot of people about tech and the implications of tech on society that we don't necessarily expect or understand well. What are some ways you think that that applies?
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          It applies to everything! From your health to how you apply for and get selected for jobs. Every facet of your life is touched by technology, and if you don't have a seat at the table when those things are being built, they will not be built for you as a use case.
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          Which is already happening—
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          Which is already happening!
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          All the time.
        </p>

        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          Right? So my favorite example of this is when the Apple HealthKit was first launched and there wasn't an app for period tracking. Like, half of the population are women, and they—depending on their age, may no longer or not yet—but everyone at some point has to deal with their period. And most women have some sort of an issue with their period; it's painful, it's irregular, whatever. Very few people have a completely normal, tolerable period. And yet—and, you know, it related to fertility and all these other things—you didn't even think to check if that was something you should build into your tracker! Everything else you're building is sort of like a nice-to-have. This is a real thing that women need. This is a painkiller, not a vitamin. And it never even occurred to you to include it. Or I see the Withings scale doesn't have a setting for, "I'm pregnant."
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          Oh, interesting.
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          So I had a pregnant friend who—you know, it tweets your weight every once a week or something, as a committing mechanism or something—and she got pregnant!
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          "Wow, you're gaining so much weight!"
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          Right! And it kept sending her these emails, like, "Don't give up! I know you've gained fifteen pounds, but you can fix—" And she was like, "Seriously? There's no pregnancy setting! I want to gain weight for the next nine months. Leave me the fuck alone!" And so those are tiny little things, right? You can opt out of a tweeting scale, you can opt out of a tracker, but when you're thinking about medical research that assumes the default use case or the default research subject is a white male, and then things like implantable devices for your heart or for whatever else—they don't build the women's model, right, or they don't think about differences in women's health that might not—a setting or a symptom in a man that wouldn't be a sign of anything but in a woman would be—none of that gets included—that becomes a problem. And you look at how you apply for jobs and what the language is that people put in job descriptions and all of the filters—
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          Ninjas, rockstars.
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          Yeah! And equally the filters that they apply. I mean, you're a perfect example of this. You don't have a computer science degree. But you are a great—right? I'm assuming—engineer. At certain jobs, if you are to apply for them, you won't make the filter because you don't have a degree, whether or not you have the skill. So one of the big things that I always talk about in my diversity and inclusion talk is thinking about a multiplicity of onramps and offramps. And thinking about—it's not just one pipeline where if you miss learning about coding at twelve and you don't tinker and hack all through high school so that you know you should major in college and you get that degree from Stanford at twenty-two, you're now shit-outta-luck on participating in the future, right? That's one path. And that's a great path. For some people. That's not realistic for a lot of other people.
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          It's interesting how—I don't know, there's this sort of aversion to hiring people who are doing bootcamps and stuff. And to some extent, I understand it because it's certainly a different education than you would get in school that's very heavily algorithms-focused—but I think part of it is also, you know, the brand naming and people feeling like it's a shortcut into this thing that I went to MIT or whatever for.
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          Well, it's funny because—so, you know, in a place that claims to be a meritocracy. In that same ecosystem, they love so much the shorthands for the hero myth. You see this in every founder story when they get written up in TechCrunch—I can't even read them anymore. It always requires a top-tier school, some sort of job—if you've had a job before—that validates you're brilliant, like a McKinsey or a Goldman—
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          Google.
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          Or Google. A core problem that you've been suffering for in some way your whole life. A "There must be a better way!" Right?  Then, boom, this totally obvious solution that, like, by the way, fifteen other startups have already tried and failed at, but whatever, right? And no one—that mythology, that founders' hero's journey, is so templated at this point that it doesn't allow for—for instance, if you're a black entrepreneur, part of your hero's journey has to have required you to have struggled and suffered from a low-income, preferably single-parent family to get to where you are. And if you happen to be a well-off black entrepreneur who had two parents and didn't struggle—
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          "Not interesting, doesn't fit my narrative."
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          It doesn't fit the narrative! There was a black male founder who *Inc.* wanted to profile, and when they found his story, which didn't include a lot of suffering, they said, "Well, this doesn't really fit the story we were looking to tell," and they didn't write about him.
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          Yeah. That's crazy.
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          And so we have these standards of MIT or Stanford or the CS degree or whatever, unless you're a white man and then you can drop out of those programs. That gives us the shorthand for, "You're in my group. You will fit in, I understand you and your problems, we're going to be fine." And if you say, "Look, I dropped out of college as a single mom, and then I learned these skills on my own, and I have no degree to prove to you that I can do it except if, I don't know, you give me a project and I will do it for you." Like, that requires cognitive load, right? That requires effort on your part to understand this person who doesn't look like you. And I would argue that that makes for a much better team and a much better hire than the stamped diploma, but it requires more effort.
          </p>
          <p>
            I think the key to all of this is the multiplicity of onramps and offramps that allow for fifty different life paths that still get you to this same place because it says you're going to see things that I don't. Right? My blind spots and my biases are actually my Achilles' heels as an entrepreneur, and if I don't hire people who see where I don't and who questions the things that I take for truth and fact when they aren't, I'm literally building holes into my product or my business plan or my whatever that, at some point, will become problematic. As we are seeing with Uber. Their culture is problematic. Not just for the people who work there, but for the people who use their service. And it will bring them down.
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          There was—I don't know if you saw this report, but Uber and Lyft had done a survey or something and realized that drivers would drive female passengers longer and keep them in the car for longer periods of time, just on average, because, you know, whatever. And how surprised can you really be? Or like Airbnb with racism. There was that woman.
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          Oh, man, yes. Who had her Tahoe place canceled.
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          Yes! How shocking can it be that these factors in the real world are going to exist in your platform unless you actively correct for them?
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          And this is also the problem with all of the "future" being built roughly in Silicon Valley. I mean, New York is certainly fighting for their fair share of the work, and Boston as well, but it really is mostly Silicon Valley. That enclave is a bubble within a bubble within a bubble. Right? Silicon Valley within San Francisco within California, which is already the most progressive state in the union.
          </p>
          <p>
            So if you're trying to understand, solve for, and be prepared for customer problems, user profiles, issues that you're going to have with customer service, thinking about America as a whole—and, quite frankly, the world if you're a global company—and you're only in this bubble within a bubble within a bubble—even if you hire diverse people, at some point, they still converge in their viewpoints of what the issue is or how many personas to plan for or whatever. There's a great article in the <i>MIT Technology Review</i>—I think it's from 2014—it's called something like "The Exotic Underclass." If you can't find it, let me know, I can send it to you. It's this amazing article that basically talks about the complete flyover states and how they've been abandoned by technology and how the issues that they face, the price points they can afford, the problems that no one's solving for them, are real problems with a giant customer base that could provide a really good business to someone who's willing to solve them. And particularly as you're thinking about sort of—it's not poverty level, but it's working class-ish—population and veterans.
          </p>
          <p>
            Veterans are hugely overlooked in terms of the resources, the support, all of—if you just wanted to focus on veterans, as a customer base, you could have a good business right now—and how they're being overlooked in terms of customers, but they're also being overlooked in terms of employees and the people kind of contribute to the building of this, and if you're willing to hire remote people, if you can have a second office in St. Louis or Minneapolis or Detroit or Kansas City, and you hire people who are from these communities, you're going to have a much more robust business, and you're going to solve real problems. Which, quite frankly, is what I am actually interested in. Yes, I would like to have a lot of money that I can then put toward causes that I care about and electing people who I think should actually be leading the country, all the things that you get when you have an influx of capital, but what I actually care about are solving problems. For real people. And not outsourcing the jobs that my mom used to do for me that I no longer want to do and now that I have enough money I can pay someone to do them for me. Right? Like, that's not—that's not making the world a better place, as Silicon Valley loves to imagine they're doing.
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          Do you think there's like—I don't know, do you have any thoughts on how to sort of unbundle Silicon Valley, I guess? Because it's sort of a lock-in effect—it feeds into itself, you know?
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          Well, so this is the challenge because if you've read Brad Feld's book, <i>Startup Communities</i>, he talks about kind of the three or four pieces you have to have to really build a startup community, right? You have to have capital—and specifically—
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          He's based in Boulder?
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          Yeah, he's based in Boulder. Specifically, capital that is risk-tolerant, right? So early-stage investors—you need the angel and seed investors. You need the founders, the entrepreneurs. You need usually a university or some sort of academic situation where you get an influx of new people on a regular basis. You have the resources of engineering or science facilities, which are the benefit of that university town piece. And then you need creatives. And that kind of mix of the business, the founders, the creatives, and then the capital—and you need the ability for serendipity, so coworking spaces, mentors, right—this is the mix that makes it possible.
          </p>
          <p>
            So if you look at a Detroit, which has been trying to become the next Boulder for five years now and is not really making it—they have some founders. They sort of have the university piece, but really that's in Ann Arbor, which is over an hour away and there's no public transit that gets you between them. You have capital, but not really risk-tolerant capital. These are people who made their money the old-fashioned way, and they don't understand what early-stage risk looks like. You don't have serendipity because you have lots of really cheap space that—everyone can get their own office, and they can be all spread out in suburbia. Dan Gilbert's trying to make this happen, but he's doing it with such a heavy hand where only the people that Dan Gilbert invests in get access to the subsidized housing and the cool DVP coworking space and the security on their blocks but not the other blocks... it's really kind of sketch, actually. So Detroit can't quite figure it out, right? And Las Vegas—Tony Hsieh's been trying to do it there. Central planning of serendipity does not seem to be going well. But! I do think you can build this if investors are willing to look at and ideally move to the middle of the country.
          </p>
          <p>
            So the guy who wrote <i>Hillbilly Elegy</i>, J.D. Vance—have you read this book? It's been blowing up.
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          I don't think so.
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          He came from the hollers of Ohio and Kentucky and wrote this book—which I take issue with in a couple ways, but it's very similar to my upbringing, so I connected in that way. Anyway, he went off to Yale Law, he became an investor at Kleiner Perkins, and he moved to Silicon Valley, and everyone's like, "Dude! Dude!" Anyway, he just announced a month ago that he's moving to Ohio. He's staying part of Kleiner, but he's moving to Ohio to look at and invest in startup in the midwest. Which is amazing! Right? So we need fifty more of those. Because there is entrepreneurial talent, but you need the investors that take them seriously and, ideally, you need investors like J.D. who come from these communities and can recognize problems, right?
          </p>
          <p>
            So when I was trying to fundraise for my first company, Quincy Apparel, we were fixing a problem around how women's clothes fit or, in our case, don't fit their bodies. And we were pitching to all of these men. This was, you know, six years ago now, and there were a lot fewer women investors than there are now, and we realized after four or five months of unsuccessful fundraising how much effort we had to put into educating them that this was actually a problem. Because they were like, "Well, I don't have any problem buying suits," and I was like, "First of all, you don't have boobs. Or a butt. But secondly, you have more variation in sizing for men's suits than women do. You get to buy a 44 long for a jacket and a 34-32 for pants. I buy an 8." Right? I have more variation in my body and less precision in my sizes. So we had to spend all this time even convincing them that there was a problem we knew existed.
          </p>
          <p>
            And you're going to see the same thing as you're trying to get out of the Valley. When the investors only see the same problems that the founders see, and you've got someone new that says, "No, no, no, for real, there's a problem over here!" And they're like, "Mmm, is that really a problem? It's not a problem for me." Right? If you're thinking about access to banking services for lower-income people who can't wait three days for a check to clear or who need to be able to take out money in increments less than $20 at a time. Or who need—if you look at a lot of the frustration with—I think it was the New York state legislation where they wanted to shut down payday lenders. And they were like, "They're ripping off poor people! It's ridiculous percentages they're charging—they should shut them down." And you're like, "Yes, from the outside, those are worse choices than banks!" But if you look at the requirements that banks require in terms of minimum amount of money in your account or the fees they charge you if you don't meet that, the three days of waiting for your check to clear—all of these problems and then you look at payday lenders, where a lot of times people just need liquidity for twenty-four hours, for forty-eight hours, and they're willing—these places stay in business not because they rip people off and no one knows, but because they actually do provide the service that people need at a price they are willing to pay.
          </p>
          <p>
            Now, do I think it should cost that much to have access to banking? No. But if you personally don't have an issue with liquidity for three days while your multi-thousand dollar check clears, then you don't even recognize where the gap in the market is. So it's a huge, intractable problem, right? That on one hand makes everyone want to throw up their hands, but on the other, I think that if there were institutional investors that said, "We actually care a lot about this," and the retirement funds, the pension funds, say, "We're going to put money behind a VC fund that is going to invest in our local community in the Midwest or in the South or in entrepreneurs that come from these types of backgrounds—not because charity, but because we think there's an untapped market that they have an advantage in seeing," then you'll have investors willing to look there, and you'll have entrepreneurs that are willing to sort of build—not willing, but able to—finally build a venture-backed company, versus a cash-flow—I hate the term—lifestyle business. But still, cash-flow-based business.
          </p>
          <p>
            You see a lot of women entrepreneurs; more than fifty percent of small business owners are women. But a lot of these are cash-flow businesses. They're very small, and they deliver a decent life for them. If they knew they had access to capital and could actually build a slightly different business plan that was based on the venture model—which is, I'm going to lose money for a while while I scale very quickly, and then I will reap it later—I think you would see a lot of existing female entrepreneurs that are able to shoot for the high-scale, much bigger kind of vision business, rather than the smaller one. I mean, look at Spanx. Sara Blakely started that with $5,000 of her own money; she's never taken outside investment. That's the reason she's the youngest female billionaire in the world. That totally could have been a venture-backed business, if any VC out there could recognize that women wanted something to smooth without having to wear—I don't know what else to use—without having to wear full-on tights all the time. But what man knows that that's a problem?!? Right? So I don't know.
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          Well, okay, that's one assumption, though, that I feel like is interesting, that scale is this necessary, unambiguously good thing.
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          Yeah! Seriously. That's a great assumption to question, as we look at places like Fab, that are like, "You scaled! Checkmark. But you failed at all seven business models you've tried to employ." No, I think that's right, I think certainly the scale at all costs and—arguably—the "I have no business model for cash-flow or real cash-flow that's going to add any point recoup the invested capital, and yet I'm going to go IPO." Hello, Snapchat! Or Twitter, for that matter.
          </p>
          <p>
            I went to business school; I studied the fundamentals of business. By the way, I was there during the entire financial crisis, so we got down to the roots of why things fell apart with the housing crisis, and I don't really see how the current attitude in the tech world is that different. Where we're saying, "I'm going to put all of this pension money into these companies that have no idea who's going to pay them at what point." Or they do—it's all advertising-based, ad-based, ad-based. But you're like, "But then who is the product?" The product is your users. At some point, we're going to get sick of being the product. We're going to either leave these platforms or we're going to use fake names or we're going to use VPN services to hide our—you know, we're getting savvy. This notion of the user who's going to perpetually give you their personal information so that you can better and better target them, that you can sell that off—that is not in perpetuity a real, sustainable business. And in the meantime, what else have you got to show? And yet, investors just keep pouring money in.
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          Do you think that there are any concrete implications of that?
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          I mean, short of all of this money just, poof, disappearing one day? And, by the way, that's everyone's pension and retirement funds? It's Fidelity and TIAA and CalPERS and all of them? I think that's the short-term implication. It's like, I want to know where my mom's retirement fund is invested because there's a chance that whole thing goes up in flames. I think it's more problematic in that that money isn't being invested in other things that would be productive assets. It's the same notion that I think you look at a lot of real estate tax treatments, and they were originally created—I did a whole class on tax law in business school, and it was super interesting—but they created a lot of these treatments to encourage the reinvestment of funds in productive capital, in assets, that would feasibly creating housing, support businesses, all these things. And instead, a lot of really big real estate investors, including our president, and a bunch of other smart quants on Wall Street just found loopholes and ways to get around rules.
          </p>
          <p>
            And it's the entire notion of the derivatives market on Wall Street. Derivatives are not productive assets. It's side bets on bets. And the fact that they get the same tax treatment as productive assets is amazing to me. So I think there could be a tax law solution for this, but I don't see a political will to do that at all right now. I think it's more problematic that this money isn't being invested in things that could be making real things. That it's being tied up in what is equivalent to gambling, in my head. And a few people are going to end up very wealthy at the end of this. But it's not going to be you, me, and my mom.
          </p>
          <p>
            Even as an early employee at a lot of these places, you're not going to end up with much. I'm all about risk and return being correlated, but the risk that the founders of Snapchat versus their third employee is not hugely—hundreds of thousands of multiples—different. And yet they will get those different treatments when it all hits the fan. It's just—it's not—I refrain from saying equitable or fair too often because the entire point of capitalism isn't fairness. I get that. But if I'm looking at it from a moral lens, of what's the role of business in society, there is a point where I say, "None of this is equitable. None of this is fair." And it's hard to reconcile that with, "Capitalism, whoo! Way better than socialism, I guess." But... to which groups? And to what end?
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          You were talking earlier about the kinds of problems that aren't being addressed. What are some areas that you maybe think are being overhyped or overemphasized? And also why, I guess? That's another thing I wonder.
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          Shouldn't the market correct for that?
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          Yeah! Don't you want to be, instead of funding yet another machine learning something something, isn't it a better bet theoretically to look for something that people aren't pouring their money into?
        </p>

        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          You would think so, but things like banking for the unbanked is going to be very low margins—but, you know, if you've got a big enough customer base, it's worth it, and there is arguably a big enough customer base for unbanked people, but your profitability per customer is going to be very low. And then just thinking about all the effort of acquisition and churn and whatever, I can see how you're like, "That's just a hard business to build. I would rather do an easy business to build." And so individually everyone makes this collective decision. Right? Overhyped. Honestly, I think VR and AR are overhyped. I know, I know there's something future, it's going to be there, even mixed reality sounds cool. But what problem are you solving for me? I can see the value in terms of training doctors, in surgery, right? Or visualizing a house instead of having to go with a real estate agent.
        </p>

        <p className="speaker interviewer">
          Christina
        </p>
        
        <p>
          These are all pretty niche applications.
        </p>

        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          Yeah! And think about the money and the brainpower being poured into virtual reality right now. And I'm just sort of—I'm just a little bit lost as to, like—is this going to solve poverty, homelessness, hunger, political instability?
        </p>

        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          Even the issues of race and gender—I think that's one thing that VR is supposed to be able to solve—I think it's very questionable whether that's the case. There was this one account of this woman who—I forget. She was playing a game in VR or something, and she was, in VR, identifiably a woman, and she was assaulted.
        </p>

        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          Yeah. Great, I don't need to go to another place to be assaulted!
        </p>

        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          This is virtual reality, and you're still getting sexually assaulted with your virtual body.
        </p>

        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          And the arguments I've heard are like, "Oh, you could go to, for instance, a job interview but disguise yourself as a man." And I was like, "I don't want to! I want to get to a world where you actually value me as a woman, not that I get to virtually put on a disguise so that you'll fucking hire me." So yes, I get it, and if truly every man out there was willing to go through a VR experience of what it feels like to be a woman in New York for a day, where the seven firefighters back there on their lunch break just ogled the two of us as we walked by, and that's just normal—maybe that would change things. But do I really think every man is going to buy their VR headset and be like, "You know what I should do first, before I play <i>Call of Duty</i>? I should experience what it's like to be harassed as a woman." Like, they're not going to do that. So it's almost like you're finding the one niche user case to justify why you want to build technology.
          </p>
          <p>
            I think machine learning is going to happen. The age of the cyborgs will come at some point. I think automated driving and automated manufacturing are coming. I think we are wholly unprepared as a society for what happens economically when that is true. And I think this is a perfect use case. The number one career in America is truck driver. They will all lose their jobs when Otto figures out how to truly automate truck driving. What are we planning on doing with them? Are we going to retrain them like the Danish do? Are we going to-there's a lot. They can't afford to buy your apps and your in-app upgrades when they no longer have a job.
          </p>
          <p>
            So alongside any technology development, I wish there was some sort of commensurate investment in understanding and preparing for the implications of that technology. I don't want to not develop automated driving just because people will lose their jobs. It's more efficient, it's safer, it's fewer resources. This is a good thing. But we have to be realistic about what it's going to affect and how that affects us collectively, even if you yourself will not lose your job over this. I think—maybe that's what I wish. For each of these things that we're so willing to pour millions of dollars in, billions even, I wish there was a ten or fifteen percent required investment in a nonprofit or academic institution that studied and developed recommendations for the implications of when this technology has succeeded. Because just because we don't want to acknowledge it doesn't mean it's not going to happen.
          </p>
          <p>
            What else is overhyped? I mean, clearly anything involving social, local, or photos, I'm done with. That was done three years ago, but anything even—I tried fashion tech six years ago, and I still see the number of startups that are like, "We're going to make a sizing recommendation engine for e-commerce." I'm like, "It's not going to work. I can give you fifty thousand reasons why it's not going to work."
          </p>
          <p>
            The Internet of Things, I think, has a lot of potential, but related to kind of the question of the implications of it... Someone tweeted this morning, Adrianne Jeffries, she's a tech journalist, "I wish I had thought of what would happen when I lose my phone when I bought smart lightbulbs." Right? And it's such a great example of, you know, there's the less nefarious cases of, "My phone is fully—the battery is dead, or I lose it, or I break it," and then there's the slightly more nefarious cases of, "I'm hacked!" Or another country decides to wage warfare on us—not by dropping bombs, but just by turning off the internet. Which sounds like a very simplistic way of saying it, but it is possible—we don't want to challenge anyone to demonstrate. But if your front door lock and your car and your lightbulbs and your pacemaker and all these things can talk to the internet, they can all be hacked, they can be turned off remotely, they can be stolen data from. And if we don't have a better way—a redundancy behind those things—we're going to be screwed. I refuse to touch anything Internet of Things. I won't do it. I have an Alexa in my living room, and even she freaks me out.
          </p>
          <p>
            The example I always point to is when an escalator breaks down, it becomes stairs, and at least you can still get where you're going. When an elevator breaks down, it becomes a coffin, where you can't get in and get out, and you can't go anywhere. I don't want to get in a self-driving car that becomes a coffin. I want to get into a self-driving car that I can still walk up the stairs if, for whatever reason, it stops working as it was designed to work. We need to figure out more safeguards and stairs use cases for anything that we expect to be connected to the internet.
        </p>

        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          Do you worry about any of the—I don't know, more doomsday AI scenarios?
        </p>

        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          I do a little. I honestly do. Simply because of where we started this conversation, which is, "Who's doing the designing?  And what defaults and biases are they programming in them?" And I think, you know, there was a great—I'm trying to remember where I read this example. There was an example of how minimum sentencing guidelines that are provided to judges—I think this was in a state level or circuit level—I don't think it was national—were based on recidivism rates. And so they—this is sort of related to "crack is judged more harshly than cocaine"—people who do this type of crime are more likely to do another crime later, and so we should punish them more harshly the first time around or whatever you want to call it. And there was a woman mathematician, maybe in Chicago, who dug into this and she was looking at like, "Well, where did that data come from?" And basically the question that I wish more people would ask is, "In what way is this data biased?" Because the assumption is that data is truth, and that's just not accurate. All data is biased in some way, and you need to know in what way it's biased so that you can then control for it. So they looked into these recidivism rates, and I forget what the big "aha" was, but basically they had taken a very skewed racial-based kind of historical records that discriminated against black men the first time around were more likely to rearrest them when something happened, and therefore that created these higher recidivism rates, which then reinforced stronger sentencing guidelines. Right? So it became like this perpetual cycle. All of which was based on biased data. And if they would just acknowledge the biased data, they could adjust for it, but they didn't.
          </p>
          <p>
            So I wish with all things AI, there was research into unconscious bias and the research methods that every social scientist has to learn in, you know, their masters program, included controlling for bias, researching into bias, and creating new ways of presenting data, recording, and sort of adjusting for bias, in all these things, so when you're building artificial intelligence on top of those data sets, you are starting with a much clearer understanding of where you're starting from. And then it requires, I would argue, a diversity of engineers working on the AI projects to then understand what biases they're bringing to the table.
        </p>
        
        <p className="speaker interviewer">
          Jackie
        </p>
        
        <p>
          I always wonder with, for instance, Apple HealthKit. Were there women on this team, and then they were like, "Hey, should we throw in some stuff about periods?" and then people were like, "No, that's super niche."
        </p>
        
        <p className="speaker interviewee">
          Christina
        </p>
        
        <p>
          Super niche! Only half of the country is relevant for it. Or! Were they too afraid to speak up because they didn't want to have to be the only woman on the team who brought up the women's issue, right? Which is just as problematic because there's tons of research that shows that minorities, both racial and gender, who talk about diversity at work are dinged. So you can't talk about it—but you're the only one who's imagining and thinking and understanding those opportunities that everyone else is missing. And so you're in this catch-22. I do wonder if there were any women on that team.
          </p>
          <p>
            No, I wish, especially for things like AI—and I know this is the exact opposite of the entire Silicon Valley ethos of run fast, break things, iterate, beta test, all the things, ship code, I get it—I wish, though, that there were some—imagine if we developed drugs that way. Imagine if pharma worked this way, where they were like, "I got a molecule! Let's rush to production, let's inject it into a bunch of people! We think it solves problems—oops, it accidentally killed 90% of the people we gave it to. Oh, well, we're just—that was the beta. It's just the beta, we're going to iterate."
          </p>
          <p>
            And I know that apps aren't the same as cancer medication. But in some ways, especially around AI and machine learning, the outcomes that they are building toward, the future they are building for, will have just as much of an impact on people as the medication that they take. And I wish there was some sort of industry review board or external kind of board that you had to submit your code to, that you had to submit your research tests to and say, "This is where we got our data, these were the experiments we ran, this is what we understand about our biases." And that they could be like, "Yes, you're ready to launch!" or, "Nope, you've completely ignored this entire group. I want to come back and I want you to address how it's going to affect them." And I get it. It's at odds with how we build everything in Silicon Valley. And yet... maybe it shouldn't be. Fast is better for dollars, but I don't know if it's better for society.
        </p>
      </div>
    )
  }
}
